# Re2CS: Rethinking Noisy Data and Optimization Reliability for Code Summarization

This is the official repository for the paper **"Rethinking Noisy Data and Optimization Reliability for Code Summarization with Large Language Models"**.

---

## ğŸ“‚ Project Structure

The repository is organized according to the following directory structure:

```text
Re2CS/
â”œâ”€â”€ baselines/            # Baseline models for comparison
â”‚   â”œâ”€â”€ EP4CS/            # Enhanced Prompting Framework for Code Summarization
â”‚   â””â”€â”€ PromptCS/         # Continuous prompt learning baseline
â”œâ”€â”€ datasets/             # Data management
â”‚   â”œâ”€â”€ CodeXglue/        # Standard benchmark dataset used for evaluation
â”‚   â””â”€â”€ augments_data/    # Refined pseudo-references generated via MA-SDA
â”œâ”€â”€ eval/                 # Evaluation modules
â”‚   â”œâ”€â”€ overlap_metrics/  # Standard metrics: BLEU, METEOR, ROUGE-L, SBERT
â”‚   â””â”€â”€ quality_metrics/  # Quality metrics: Factual Correctness, Hallucination, etc.
â”œâ”€â”€ frameworks/           # Core technical implementations
â”‚   â”œâ”€â”€ margin_DPO/       # Implementation of Margin-DPO optimization
â”‚   â””â”€â”€ masda_pipeline/   # Multi-agent data augmentation pipeline
â”œâ”€â”€ utils/                # General utility functions
â””â”€â”€ main.py               # Main entry point for training and evaluation

```
---
## ğŸ“ Download and Prepare Datasets

You can download the datasets from https://huggingface.co/datasets/qustfmy/Re2CS.


## ğŸš€ Quick Start

### 1. Environment Setup

```bash
git clone https://github.com/qustfmy/Re2CS.git
cd Re2CS
pip install -r requirements.txt

```

### 2. ğŸ“Š Data Augmentation (MA-SDA)

Generate high-quality pseudo-references for your training set:

```bash
python frameworks/masda_pipeline/run_agents.py --input datasets/CodeXglue/python --output datasets/augments_data/python

```

### 3. Training with Margin-DPO

Train the LLM using the joint objective of SFT and Margin-DPO:

```bash
python main.py --method margin_DPO --lambda_sft 0.3 --dataset datasets/augments_data/python

```
---

## ğŸ“Š Experimental Results

Extensive experiments across six programming languages (Python, Java, Go, PHP, JavaScript, Ruby) demonstrate the effectiveness of Re2CS:

* 
**Factual Error Reduction**: Factual errors were reduced from 34.2% (GT) to 6.6% (Fusioner).


* 
**Hallucination Suppression**: Hallucination rates dropped from 13.9% to 1.6%.


* 
**Downstream Utility**: Code search performance (MRR) improved by an average of 11.2%.


* 
**Scale Efficiency**: A 0.5B model tuned with Re2CS matches the zero-shot performance of GPT-4o.



---

## ğŸ“ Citation

If you use Re2CS in your research, please cite our paper.
